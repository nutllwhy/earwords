// ä¾‹å¥éŸ³é¢‘ç”Ÿæˆè„šæœ¬ - ä½¿ç”¨ Azure TTS æˆ–ç³»ç»Ÿ TTS
// è¿è¡Œ: node generate-audio.mjs

import fs from 'fs';
import path from 'path';
import { execSync } from 'child_process';

// é…ç½®
const CONFIG = {
  // ä½¿ç”¨ç³»ç»Ÿ TTS (macOS say å‘½ä»¤) æˆ– Azure TTS
  useSystemTTS: true,
  
  // Azure TTS é…ç½® (å¦‚æœä½¿ç”¨)
  azure: {
    key: process.env.AZURE_TTS_KEY || '',
    region: process.env.AZURE_TTS_REGION || 'eastasia',
    voice: 'en-US-JennyNeural' // æˆ– en-US-GuyNeural
  },
  
  // è¾“å‡ºç›®å½•
  audioDir: './audio-examples',
  
  // åŒæ—¶å¤„ç†çš„å¹¶å‘æ•°
  concurrency: 5,
  
  // è¯·æ±‚é—´éš” (ms)
  delayMs: 500
};

// ç¡®ä¿éŸ³é¢‘ç›®å½•å­˜åœ¨
if (!fs.existsSync(CONFIG.audioDir)) {
  fs.mkdirSync(CONFIG.audioDir, { recursive: true });
}

// åŠ è½½è¯åº“
const vocabFile = fs.existsSync('./ielts-vocabulary-with-phonetics.json') 
  ? './ielts-vocabulary-with-phonetics.json'
  : './ielts-words-simple.json';
  
const vocabData = JSON.parse(fs.readFileSync(vocabFile, 'utf-8'));

// åŠ è½½è¿›åº¦
const PROGRESS_FILE = './audio-progress.json';
let progress = { completed: 0, failed: [], generated: [] };
if (fs.existsSync(PROGRESS_FILE)) {
  progress = JSON.parse(fs.readFileSync(PROGRESS_FILE, 'utf-8'));
  console.log(`ğŸ”„ æ¢å¤è¿›åº¦: å·²å®Œæˆ ${progress.completed}/${vocabData.length}`);
}

// ä½¿ç”¨ macOS ç³»ç»Ÿ TTS (say å‘½ä»¤)
async function generateWithSystemTTS(text, wordId) {
  const outputPath = path.join(CONFIG.audioDir, `${wordId}.mp3`);
  
  try {
    // ä½¿ç”¨ say å‘½ä»¤ç”ŸæˆéŸ³é¢‘ï¼Œç„¶åè½¬æ¢ä¸º mp3
    const aiffPath = outputPath.replace('.mp3', '.aiff');
    
    // æ¸…ç†æ–‡æœ¬ä¸­çš„ç‰¹æ®Šå­—ç¬¦
    const cleanText = text.replace(/["\\]/g, '');
    
    execSync(`say -v "Samantha" -o "${aiffPath}" "${cleanText}"`, {
      timeout: 10000
    });
    
    // è½¬æ¢ä¸º mp3 (éœ€è¦ lameï¼Œå¦‚æœæ²¡æœ‰åˆ™ä¿ç•™ aiff)
    try {
      execSync(`lame -m m "${aiffPath}" "${outputPath}" --silent`, { timeout: 10000 });
      fs.unlinkSync(aiffPath);
    } catch (e) {
      // lame ä¸å¯ç”¨ï¼Œä¿ç•™ aiff æ ¼å¼
      return { success: true, path: aiffPath, format: 'aiff' };
    }
    
    return { success: true, path: outputPath, format: 'mp3' };
  } catch (error) {
    return { success: false, error: error.message };
  }
}

// ä½¿ç”¨ Azure TTS
async function generateWithAzureTTS(text, wordId) {
  // è¿™é‡Œå¯ä»¥å®ç° Azure TTS API è°ƒç”¨
  // æš‚æ—¶è¿”å›æœªå®ç°
  return { success: false, error: 'Azure TTS not implemented yet' };
}

// ç”Ÿæˆå•ä¸ªéŸ³é¢‘
async function generateAudio(wordItem, index) {
  const wordId = wordItem.id;
  const word = wordItem.word;
  const example = wordItem.example;
  
  // è·³è¿‡å·²ç”Ÿæˆçš„
  if (progress.generated.includes(wordId)) {
    return { skipped: true };
  }
  
  // è·³è¿‡æ— ä¾‹å¥çš„
  if (!example || example === '-') {
    progress.generated.push(wordId);
    progress.completed++;
    return { skipped: true, reason: 'no_example' };
  }
  
  console.log(`[${index + 1}/${vocabData.length}] ${word}`);
  console.log(`  ğŸ“ ${example.substring(0, 60)}...`);
  
  // æ„å»ºæœ—è¯»æ–‡æœ¬: å•è¯ + ä¾‹å¥
  const textToRead = `${word}. ${example}`;
  
  let result;
  if (CONFIG.useSystemTTS) {
    result = await generateWithSystemTTS(textToRead, wordId);
  } else {
    result = await generateWithAzureTTS(textToRead, wordId);
  }
  
  if (result.success) {
    progress.generated.push(wordId);
    progress.completed++;
    console.log(`  âœ… ${result.format} ${result.path}`);
  } else {
    progress.failed.push({ wordId, word, error: result.error });
    console.log(`  âŒ ${result.error}`);
  }
  
  // æ¯10ä¸ªä¿å­˜ä¸€æ¬¡
  if ((index + 1) % 10 === 0) {
    fs.writeFileSync(PROGRESS_FILE, JSON.stringify(progress, null, 2));
    console.log(`ğŸ’¾ è¿›åº¦å·²ä¿å­˜`);
  }
  
  return result;
}

// æ‰¹å¤„ç†å‡½æ•°
async function processBatch(startIdx, batchSize) {
  const batch = vocabData.slice(startIdx, startIdx + batchSize);
  const promises = batch.map((item, idx) => 
    generateAudio(item, startIdx + idx).then(result => {
      if (idx < batch.length - 1) {
        return new Promise(resolve => setTimeout(() => resolve(result), CONFIG.delayMs));
      }
      return result;
    })
  );
  return Promise.all(promises);
}

// ä¸»å‡½æ•°
async function main() {
  console.log('ğŸš€ å¼€å§‹ç”Ÿæˆä¾‹å¥éŸ³é¢‘...');
  console.log(`ğŸ“Š æ€»è®¡: ${vocabData.length} ä¸ªå•è¯`);
  console.log(`ğŸ”§ ä½¿ç”¨: ${CONFIG.useSystemTTS ? 'ç³»ç»Ÿ TTS (macOS say)' : 'Azure TTS'}`);
  console.log(`ğŸ“ è¾“å‡ºç›®å½•: ${CONFIG.audioDir}`);
  console.log('');
  
  // ä»ä¸Šæ¬¡ä¸­æ–­å¤„ç»§ç»­
  const startIndex = progress.completed;
  
  // æŒ‰æ‰¹æ¬¡å¤„ç†
  for (let i = startIndex; i < vocabData.length; i += CONFIG.concurrency) {
    await processBatch(i, CONFIG.concurrency);
  }
  
  // æœ€ç»ˆä¿å­˜
  fs.writeFileSync(PROGRESS_FILE, JSON.stringify(progress, null, 2));
  
  console.log('\nâœ… å®Œæˆï¼');
  console.log(`æˆåŠŸ: ${progress.completed}`);
  console.log(`å¤±è´¥: ${progress.failed.length}`);
  console.log(`\néŸ³é¢‘æ–‡ä»¶ä½äº: ${CONFIG.audioDir}/`);
  
  // ç”ŸæˆéŸ³é¢‘ç´¢å¼•æ–‡ä»¶
  const audioIndex = vocabData
    .filter(item => progress.generated.includes(item.id))
    .map(item => ({
      id: item.id,
      word: item.word,
      audioFile: `${item.id}.mp3`
    }));
  
  fs.writeFileSync('./audio-index.json', JSON.stringify(audioIndex, null, 2));
  console.log(`ğŸ“‘ éŸ³é¢‘ç´¢å¼•å·²ç”Ÿæˆ: audio-index.json`);
}

// å¤„ç†ä¸­æ–­
process.on('SIGINT', () => {
  console.log('\n\nâš ï¸ ä¸­æ–­ä¿å­˜ä¸­...');
  fs.writeFileSync(PROGRESS_FILE, JSON.stringify(progress, null, 2));
  console.log('è¿›åº¦å·²ä¿å­˜');
  process.exit(0);
});

main().catch(console.error);
