//
//  AudioPlayerManager.swift
//  EarWords
//
//  éŸ³é¢‘æ’­æ”¾å™¨ç®¡ç†å™¨ - å®Œæ•´ç‰ˆ
//  æ”¯æŒï¼šåå°æ’­æ”¾ã€é”å±æ§åˆ¶ã€éŸ³é¢‘åŠ è½½ä¼˜å…ˆçº§ã€å¤šç§æ’­æ”¾æ¨¡å¼
//

import Foundation
import AVFoundation
import MediaPlayer
import Combine

// MARK: - æ’­æ”¾æ¨¡å¼

enum PlaybackMode: String, CaseIterable {
    case sequential = "é¡ºåºæ’­æ”¾"   // æŒ‰é¡ºåºæ’­æ”¾
    case random = "éšæœºæ’­æ”¾"       // éšæœºæ‰“ä¹±
    case spaced = "é—´éš”é‡å¤"       // æ ¹æ®æŒæ¡ç¨‹åº¦æ™ºèƒ½é‡å¤
}

// MARK: - æ’­æ”¾çŠ¶æ€

enum PlayerState: Equatable {
    case idle
    case loading
    case playing
    case paused
    case finished
    case error(String)
}

// MARK: - æ’­æ”¾é˜Ÿåˆ—é¡¹

struct PlaybackQueueItem: Identifiable, Equatable {
    let id = UUID()
    let word: WordEntity
    var priority: Double = 0      // ç”¨äºé—´éš”é‡å¤æ¨¡å¼çš„ä¼˜å…ˆçº§
    var playCount: Int = 0        // æ’­æ”¾æ¬¡æ•°
    var lastPlayed: Date?         // ä¸Šæ¬¡æ’­æ”¾æ—¶é—´
    var audioSource: AudioSource = .unknown  // éŸ³é¢‘æ¥æº
}

// MARK: - éŸ³é¢‘æ¥æº

enum AudioSource {
    case documents       // Documentsç›®å½•ï¼ˆå·²ä¸‹è½½ï¼‰
    case bundle          // Bundleèµ„æº
    case audioExamples   // Data/audio-examples/ç›®å½•
    case online          // åœ¨çº¿URL
    case tts             // TTSé™çº§
    case unknown
}

// MARK: - éŸ³é¢‘æ’­æ”¾å™¨ç®¡ç†å™¨

class AudioPlayerManager: NSObject, ObservableObject {
    
    // MARK: - å•ä¾‹
    static let shared = AudioPlayerManager()
    
    // MARK: - å‘å¸ƒå±æ€§
    @Published var currentState: PlayerState = .idle
    @Published var currentItem: PlaybackQueueItem?
    @Published var currentIndex: Int = 0
    @Published var progress: Double = 0
    @Published var currentTime: TimeInterval = 0
    @Published var totalDuration: TimeInterval = 0
    @Published var playbackMode: PlaybackMode = .sequential
    @Published var queue: [PlaybackQueueItem] = []
    @Published var isShuffleEnabled: Bool = false
    @Published var playbackSpeed: Float = 1.0
    @Published var currentAudioSource: AudioSource = .unknown
    
    // å®Œæˆå›è°ƒ
    var onPlaybackFinished: (() -> Void)?
    var onTrackChanged: ((PlaybackQueueItem) -> Void)?
    
    // MARK: - ç§æœ‰å±æ€§
    private var audioPlayer: AVAudioPlayer?
    private var progressTimer: Timer?
    private var commandCenter = MPRemoteCommandCenter.shared()
    private var nowPlayingInfo = [String: Any]()
    private var audioSession: AVAudioSession { AVAudioSession.sharedInstance() }
    private var ttsSynthesizer = AVSpeechSynthesizer()
    
    // é—´éš”é‡å¤æ¨¡å¼çš„æ’­æ”¾å†å²
    private var spacedRepetitionHistory: [Int32: [Date]] = [:]
    private var originalQueue: [PlaybackQueueItem] = []  // åŸå§‹é˜Ÿåˆ—ï¼ˆç”¨äºé¡ºåºæ¨¡å¼æ¢å¤ï¼‰
    
    // MARK: - åˆå§‹åŒ–
    private override init() {
        super.init()
        setupAudioSession()
        setupRemoteCommandCenter()
        setupTTS()
    }
    
    // MARK: - éŸ³é¢‘ä¼šè¯é…ç½®
    private func setupAudioSession() {
        do {
            // é…ç½®ä¸ºæ’­æ”¾æ¨¡å¼ï¼Œæ”¯æŒåå°æ’­æ”¾
            try audioSession.setCategory(
                .playback,
                mode: .default,
                options: [.defaultToSpeaker, .allowBluetooth, .allowBluetoothA2DP]
            )
            try audioSession.setActive(true)
            print("âœ… éŸ³é¢‘ä¼šè¯é…ç½®æˆåŠŸ")
        } catch {
            print("âŒ é…ç½®éŸ³é¢‘ä¼šè¯å¤±è´¥: \(error)")
        }
    }
    
    // MARK: - TTSé…ç½®
    private func setupTTS() {
        ttsSynthesizer.delegate = self
    }
    
    // MARK: - è¿œç¨‹æ§åˆ¶ä¸­å¿ƒè®¾ç½®ï¼ˆé”å±æ§åˆ¶ï¼‰
    private func setupRemoteCommandCenter() {
        // æ’­æ”¾å‘½ä»¤
        commandCenter.playCommand.addTarget { [weak self] _ in
            self?.play()
            return .success
        }
        
        // æš‚åœå‘½ä»¤
        commandCenter.pauseCommand.addTarget { [weak self] _ in
            self?.pause()
            return .success
        }
        
        // ä¸‹ä¸€é¦–å‘½ä»¤
        commandCenter.nextTrackCommand.addTarget { [weak self] _ in
            self?.nextTrack()
            return .success
        }
        
        // ä¸Šä¸€é¦–å‘½ä»¤
        commandCenter.previousTrackCommand.addTarget { [weak self] _ in
            self?.previousTrack()
            return .success
        }
        
        // æ‹–åŠ¨è¿›åº¦æ¡
        commandCenter.changePlaybackPositionCommand.addTarget { [weak self] event in
            guard let self = self,
                  let positionEvent = event as? MPChangePlaybackPositionCommandEvent else {
                return .commandFailed
            }
            self.seek(to: positionEvent.positionTime)
            return .success
        }
        
        // å¯ç”¨å‘½ä»¤
        commandCenter.playCommand.isEnabled = true
        commandCenter.pauseCommand.isEnabled = true
        commandCenter.nextTrackCommand.isEnabled = true
        commandCenter.previousTrackCommand.isEnabled = true
        commandCenter.changePlaybackPositionCommand.isEnabled = true
        
        print("âœ… è¿œç¨‹æ§åˆ¶ä¸­å¿ƒé…ç½®æˆåŠŸ")
    }
    
    // MARK: - æ’­æ”¾é˜Ÿåˆ—ç®¡ç†
    
    /// è®¾ç½®æ’­æ”¾åˆ—è¡¨
    func setPlaylist(words: [WordEntity], mode: PlaybackMode = .sequential) {
        self.playbackMode = mode
        self.queue = words.map { PlaybackQueueItem(word: $0) }
        self.originalQueue = self.queue
        
        switch mode {
        case .sequential:
            // æŒ‰å•è¯IDæ’åº
            queue.sort { $0.word.id < $1.word.id }
            
        case .random:
            // éšæœºæ‰“ä¹±
            queue.shuffle()
            
        case .spaced:
            // æ ¹æ®æŒæ¡ç¨‹åº¦æ’åºï¼ˆä¸ç†Ÿæ‚‰ä¼˜å…ˆï¼‰
            sortQueueBySpacedRepetition()
        }
        
        currentIndex = 0
        if let firstItem = queue.first {
            currentItem = firstItem
            loadAudio(for: firstItem.word)
        }
        
        print("âœ… æ’­æ”¾åˆ—è¡¨è®¾ç½®å®Œæˆ: \(queue.count) ä¸ªå•è¯, æ¨¡å¼: \(mode.rawValue)")
    }
    
    /// æ›´æ–°é—´éš”é‡å¤ä¼˜å…ˆçº§
    private func updateSpacedRepetitionPriorities() {
        for index in queue.indices {
            let item = queue[index]
            let word = item.word
            
            // è®¡ç®—ä¼˜å…ˆçº§ï¼šä¸ç†Ÿæ‚‰çš„è¯ä¼˜å…ˆçº§é«˜
            var priority = 1.0
            
            // åŸºäºæ­£ç¡®ç‡çš„ä¼˜å…ˆçº§ï¼ˆæ­£ç¡®ç‡è¶Šä½ä¼˜å…ˆçº§è¶Šé«˜ï¼‰
            let accuracy = word.accuracy
            if accuracy < 0.3 {
                priority += 3.0
            } else if accuracy < 0.5 {
                priority += 2.0
            } else if accuracy < 0.8 {
                priority += 1.0
            }
            
            // åŸºäºéš¾åº¦çš„ä¼˜å…ˆçº§ï¼ˆéš¾åº¦è¶Šé«˜ä¼˜å…ˆçº§è¶Šé«˜ï¼‰
            let difficulty = Double(word.difficulty)
            priority += (6.0 - difficulty) * 0.3
            
            // åŸºäºå­¦ä¹ çŠ¶æ€çš„ä¼˜å…ˆçº§
            switch word.status {
            case "learning":
                priority += 1.5
            case "new":
                priority += 1.0
            case "mastered":
                priority += 0.2
            default:
                break
            }
            
            // åŸºäºå¤ä¹ æ¬¡æ•°çš„ä¼˜å…ˆçº§ï¼ˆå¤ä¹ æ¬¡æ•°å°‘çš„ä¼˜å…ˆï¼‰
            priority += max(0, 5.0 - Double(word.reviewCount)) * 0.2
            
            // åŸºäºæ’­æ”¾æ¬¡æ•°çš„è¡°å‡ï¼ˆæ’­æ”¾æ¬¡æ•°å¤šçš„é™ä½ä¼˜å…ˆçº§ï¼‰
            priority -= Double(item.playCount) * 0.4
            
            // åŸºäºæ—¶é—´é—´éš”çš„è¡°å‡ï¼ˆåˆšæ’­æ”¾è¿‡çš„é™ä½ä¼˜å…ˆçº§ï¼‰
            if let lastPlayed = item.lastPlayed {
                let minutesSince = Date().timeIntervalSince(lastPlayed) / 60
                priority += min(2.0, minutesSince / 15)  // æ¯15åˆ†é’Ÿå¢åŠ ä¸€ç‚¹ä¼˜å…ˆçº§
            }
            
            // åŸºäºè¿ç»­æ­£ç¡®æ¬¡æ•°çš„ä¼˜å…ˆçº§ï¼ˆè¿ç»­æ­£ç¡®å¤šçš„é™ä½ä¼˜å…ˆçº§ï¼‰
            priority -= Double(word.streak) * 0.1
            
            queue[index].priority = max(0.1, priority)  // æœ€å°ä¼˜å…ˆçº§0.1
        }
    }
    
    /// æŒ‰é—´éš”é‡å¤æ’åºé˜Ÿåˆ—
    private func sortQueueBySpacedRepetition() {
        updateSpacedRepetitionPriorities()
        queue.sort { $0.priority > $1.priority }
        print("ğŸ”„ é—´éš”é‡å¤é˜Ÿåˆ—å·²æ’åºï¼Œå‰5ä¸ªä¼˜å…ˆçº§: \(queue.prefix(5).map { "\($0.word.word):\(String(format: "%.1f", $0.priority))" })")
    }
    
    /// åˆ·æ–°é—´éš”é‡å¤é˜Ÿåˆ—
    func refreshSpacedRepetitionQueue() {
        guard playbackMode == .spaced else { return }
        sortQueueBySpacedRepetition()
        // é‡æ–°å®šä½å½“å‰æ’­æ”¾é¡¹
        if let currentItem = currentItem,
           let newIndex = queue.firstIndex(where: { $0.id == currentItem.id }) {
            currentIndex = newIndex
        }
    }
    
    // MARK: - éŸ³é¢‘åŠ è½½ï¼ˆä¼˜å…ˆçº§å®ç°ï¼‰
    
    /// åŠ è½½éŸ³é¢‘ - æŒ‰ä¼˜å…ˆçº§æŸ¥æ‰¾
    func loadAudio(for word: WordEntity) {
        currentState = .loading
        
        // ä¼˜å…ˆçº§1: Documentsç›®å½•ï¼ˆå·²ä¸‹è½½ï¼‰
        if let audioPath = word.exampleAudioPath, !audioPath.isEmpty {
            let fullPath = getDocumentsDirectory().appendingPathComponent(audioPath)
            if FileManager.default.fileExists(atPath: fullPath.path) {
                print("ğŸ“ ä» Documents åŠ è½½éŸ³é¢‘: \(audioPath)")
                loadAudio(from: fullPath, source: .documents)
                return
            }
        }
        
        // ä¼˜å…ˆçº§2: Bundleèµ„æºï¼ˆå•è¯å.aiffï¼‰
        let bundlePaths = [
            Bundle.main.path(forResource: word.word, ofType: "aiff"),
            Bundle.main.path(forResource: word.word.lowercased(), ofType: "aiff"),
            Bundle.main.path(forResource: word.word, ofType: "mp3"),
            Bundle.main.path(forResource: word.word.lowercased(), ofType: "mp3"),
            Bundle.main.path(forResource: word.word, ofType: "wav"),
            Bundle.main.path(forResource: word.word.lowercased(), ofType: "wav")
        ].compactMap { $0 }
        
        for path in bundlePaths {
            if FileManager.default.fileExists(atPath: path) {
                print("ğŸ“¦ ä» Bundle åŠ è½½éŸ³é¢‘: \(path)")
                loadAudio(from: URL(fileURLWithPath: path), source: .bundle)
                return
            }
        }
        
        // ä¼˜å…ˆçº§3: Data/audio-examples/ ç›®å½•
        let examplesDir = getAudioExamplesDirectory()
        let exampleFiles = [
            "\(word.word).aiff",
            "\(word.word.lowercased()).aiff",
            "\(word.word).mp3",
            "\(word.word.lowercased()).mp3"
        ]
        
        for file in exampleFiles {
            let filePath = examplesDir.appendingPathComponent(file)
            if FileManager.default.fileExists(atPath: filePath.path) {
                print("ğŸµ ä» audio-examples åŠ è½½éŸ³é¢‘: \(file)")
                loadAudio(from: filePath, source: .audioExamples)
                return
            }
        }
        
        // ä¼˜å…ˆçº§4: åœ¨çº¿URL
        if let audioUrl = word.audioUrl, let url = URL(string: audioUrl) {
            print("ğŸŒ å°è¯•åŠ è½½åœ¨çº¿éŸ³é¢‘: \(url)")
            loadOnlineAudio(from: url, word: word)
            return
        }
        
        // ä¼˜å…ˆçº§5: TTSé™çº§
        print("ğŸ”Š ä½¿ç”¨ TTS é™çº§")
        loadTTS(for: word)
    }
    
    /// ä»æœ¬åœ°æ–‡ä»¶åŠ è½½éŸ³é¢‘
    private func loadAudio(from url: URL, source: AudioSource) {
        do {
            audioPlayer = try AVAudioPlayer(contentsOf: url)
            audioPlayer?.delegate = self
            audioPlayer?.prepareToPlay()
            audioPlayer?.enableRate = true
            audioPlayer?.rate = playbackSpeed
            
            totalDuration = audioPlayer?.duration ?? 0
            currentState = .paused
            currentAudioSource = source
            
            // æ›´æ–°é˜Ÿåˆ—é¡¹çš„éŸ³é¢‘æ¥æº
            if var item = currentItem {
                item.audioSource = source
                currentItem = item
                if let index = queue.firstIndex(where: { $0.id == item.id }) {
                    queue[index].audioSource = source
                }
            }
            
            updateNowPlayingInfo()
            print("âœ… éŸ³é¢‘åŠ è½½æˆåŠŸ: \(url.lastPathComponent), æ—¶é•¿: \(totalDuration.formatted)")
        } catch {
            print("âŒ åŠ è½½éŸ³é¢‘å¤±è´¥: \(error)")
            currentState = .error("æ— æ³•åŠ è½½éŸ³é¢‘: \(error.localizedDescription)")
        }
    }
    
    /// åŠ è½½åœ¨çº¿éŸ³é¢‘
    private func loadOnlineAudio(from url: URL, word: WordEntity) {
        // ä¸‹è½½å¹¶ç¼“å­˜éŸ³é¢‘
        let task = URLSession.shared.downloadTask(with: url) { [weak self] location, response, error in
            DispatchQueue.main.async {
                if let error = error {
                    print("âŒ ä¸‹è½½åœ¨çº¿éŸ³é¢‘å¤±è´¥: \(error)")
                    self?.loadTTS(for: word)
                    return
                }
                
                guard let location = location else {
                    print("âŒ åœ¨çº¿éŸ³é¢‘ä¸‹è½½ä½ç½®ä¸ºç©º")
                    self?.loadTTS(for: word)
                    return
                }
                
                // ç§»åŠ¨åˆ°ä¸´æ—¶ç›®å½•
                let tempDir = FileManager.default.temporaryDirectory
                let tempFile = tempDir.appendingPathComponent("\(word.word)_online.mp3")
                
                do {
                    if FileManager.default.fileExists(atPath: tempFile.path) {
                        try FileManager.default.removeItem(at: tempFile)
                    }
                    try FileManager.default.moveItem(at: location, to: tempFile)
                    self?.loadAudio(from: tempFile, source: .online)
                } catch {
                    print("âŒ ç§»åŠ¨ä¸‹è½½æ–‡ä»¶å¤±è´¥: \(error)")
                    self?.loadTTS(for: word)
                }
            }
        }
        task.resume()
    }
    
    /// ä½¿ç”¨ TTS æ’­æ”¾
    private func loadTTS(for word: WordEntity?) {
        guard let word = word else { return }
        
        currentAudioSource = .tts
        currentState = .playing  // TTSç›´æ¥å¼€å§‹æ’­æ”¾
        
        // æ›´æ–°é˜Ÿåˆ—é¡¹
        if var item = currentItem {
            item.audioSource = .tts
            currentItem = item
            if let index = queue.firstIndex(where: { $0.id == item.id }) {
                queue[index].audioSource = .tts
            }
        }
        
        // é¢„ä¼°TTSæ—¶é•¿
        totalDuration = Double(word.word.count) * 0.25 + 0.5
        
        updateNowPlayingInfo()
        speakWithTTS(word: word)
        
        print("ğŸ”Š TTS æ’­æ”¾: \(word.word)")
    }
    
    /// TTSè¯­éŸ³åˆæˆ
    private func speakWithTTS(word: WordEntity) {
        ttsSynthesizer.stopSpeaking(at: .immediate)
        
        // æ„å»ºæœ—è¯»å†…å®¹ï¼šå•è¯ + é‡Šä¹‰
        var textToSpeak = word.word
        if let meaning = word.meaning, !meaning.isEmpty {
            // ç®€åŒ–é‡Šä¹‰ï¼Œåªå–ä¸»è¦éƒ¨åˆ†
            let simplifiedMeaning = meaning.components(separatedBy: "ï¼›").first ?? meaning
            textToSpeak += ", \(simplifiedMeaning)"
        }
        
        let utterance = AVSpeechUtterance(string: textToSpeak)
        utterance.voice = AVSpeechSynthesisVoice(language: "en-US")
        utterance.rate = 0.4  // è¾ƒæ…¢è¯­é€Ÿ
        utterance.pitchMultiplier = 1.0
        utterance.volume = 1.0
        
        ttsSynthesizer.speak(utterance)
    }
    
    // MARK: - æ’­æ”¾æ§åˆ¶
    
    /// æ’­æ”¾
    func play() {
        // å¦‚æœæ˜¯TTSæ¨¡å¼
        if currentAudioSource == .tts {
            if !ttsSynthesizer.isSpeaking {
                if let word = currentItem?.word {
                    speakWithTTS(word: word)
                }
            } else {
                ttsSynthesizer.continueSpeaking()
            }
            currentState = .playing
            startProgressTimer()
            updateNowPlayingInfo()
            return
        }
        
        // æ™®é€šéŸ³é¢‘æ’­æ”¾
        guard let player = audioPlayer else {
            if let word = currentItem?.word {
                loadAudio(for: word)
            }
            return
        }
        
        player.play()
        currentState = .playing
        startProgressTimer()
        updateNowPlayingInfo()
        print("â–¶ï¸ æ’­æ”¾")
    }
    
    /// æš‚åœ
    func pause() {
        if currentAudioSource == .tts {
            ttsSynthesizer.pauseSpeaking(at: .immediate)
        }
        
        audioPlayer?.pause()
        currentState = .paused
        stopProgressTimer()
        updateNowPlayingInfo()
        print("â¸ï¸ æš‚åœ")
    }
    
    /// åœæ­¢
    func stop() {
        ttsSynthesizer.stopSpeaking(at: .immediate)
        audioPlayer?.stop()
        audioPlayer?.currentTime = 0
        currentState = .idle
        progress = 0
        currentTime = 0
        stopProgressTimer()
        updateNowPlayingInfo()
    }
    
    /// è·³è½¬åˆ°æŒ‡å®šä½ç½®
    func seek(to time: TimeInterval) {
        guard currentAudioSource != .tts else { return }  // TTSä¸æ”¯æŒè·³è½¬
        
        guard let player = audioPlayer else { return }
        player.currentTime = min(max(0, time), player.duration)
        currentTime = player.currentTime
        progress = player.duration > 0 ? player.currentTime / player.duration : 0
        updateNowPlayingInfo()
    }
    
    /// ä¸‹ä¸€é¦–
    func nextTrack() {
        guard !queue.isEmpty else { return }
        
        // æ›´æ–°å½“å‰é¡¹çš„æ’­æ”¾ç»Ÿè®¡
        if currentItem != nil {
            updateCurrentItemStats()
        }
        
        // ç¡®å®šä¸‹ä¸€é¦–
        let nextIndex: Int
        switch playbackMode {
        case .sequential:
            nextIndex = (currentIndex + 1) % queue.count
            
        case .random:
            nextIndex = Int.random(in: 0..<queue.count)
            
        case .spaced:
            // æ›´æ–°ä¼˜å…ˆçº§å¹¶é‡æ–°æ’åº
            sortQueueBySpacedRepetition()
            nextIndex = 0
        }
        
        currentIndex = nextIndex
        currentItem = queue[nextIndex]
        
        if let word = currentItem?.word {
            loadAudio(for: word)
            play()
            onTrackChanged?(currentItem!)
        }
        
        print("â­ï¸ ä¸‹ä¸€é¦–: \(currentItem?.word.word ?? "æœªçŸ¥")")
    }
    
    /// ä¸Šä¸€é¦–
    func previousTrack() {
        guard !queue.isEmpty else { return }
        
        // æ›´æ–°å½“å‰é¡¹çš„æ’­æ”¾ç»Ÿè®¡
        if currentItem != nil {
            updateCurrentItemStats()
        }
        
        let prevIndex = (currentIndex - 1 + queue.count) % queue.count
        currentIndex = prevIndex
        currentItem = queue[prevIndex]
        
        if let word = currentItem?.word {
            loadAudio(for: word)
            play()
            onTrackChanged?(currentItem!)
        }
        
        print("â®ï¸ ä¸Šä¸€é¦–: \(currentItem?.word.word ?? "æœªçŸ¥")")
    }
    
    /// è·³è½¬åˆ°æŒ‡å®šé¡¹
    func jumpToItem(at index: Int) {
        guard queue.indices.contains(index) else { return }
        
        // æ›´æ–°å½“å‰é¡¹ç»Ÿè®¡
        if currentItem != nil {
            updateCurrentItemStats()
        }
        
        currentIndex = index
        currentItem = queue[index]
        
        if let word = currentItem?.word {
            loadAudio(for: word)
            play()
            onTrackChanged?(currentItem!)
        }
        
        print("â¯ï¸ è·³è½¬åˆ°: \(currentItem?.word.word ?? "æœªçŸ¥") [\(index)]")
    }
    
    /// æ›´æ–°å½“å‰é¡¹æ’­æ”¾ç»Ÿè®¡
    private func updateCurrentItemStats() {
        guard var item = currentItem else { return }
        item.playCount += 1
        item.lastPlayed = Date()
        currentItem = item
        
        if let index = queue.firstIndex(where: { $0.id == item.id }) {
            queue[index].playCount = item.playCount
            queue[index].lastPlayed = item.lastPlayed
        }
    }
    
    /// åˆ‡æ¢æ’­æ”¾é€Ÿåº¦
    func setPlaybackSpeed(_ speed: Float) {
        playbackSpeed = speed
        audioPlayer?.rate = speed
        updateNowPlayingInfo()
    }
    
    // MARK: - è¿›åº¦ç®¡ç†
    
    private func startProgressTimer() {
        stopProgressTimer()
        progressTimer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { [weak self] _ in
            self?.updateProgress()
        }
    }
    
    private func stopProgressTimer() {
        progressTimer?.invalidate()
        progressTimer = nil
    }
    
    private func updateProgress() {
        if currentAudioSource == .tts {
            // TTSè¿›åº¦æ¨¡æ‹Ÿ
            currentTime += 0.1
            if currentTime >= totalDuration {
                progress = 1.0
                ttsDidFinish()
            } else {
                progress = currentTime / totalDuration
            }
            return
        }
        
        guard let player = audioPlayer else { return }
        
        currentTime = player.currentTime
        totalDuration = player.duration
        progress = player.duration > 0 ? player.currentTime / player.duration : 0
        
        updateNowPlayingInfo()
    }
    
    /// TTSå®Œæˆå¤„ç†
    private func ttsDidFinish() {
        stopProgressTimer()
        currentState = .finished
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) { [weak self] in
            self?.nextTrack()
        }
    }
    
    // MARK: - Now Playing ä¿¡æ¯æ›´æ–°ï¼ˆé”å±æ˜¾ç¤ºï¼‰
    
    private func updateNowPlayingInfo() {
        guard let item = currentItem else {
            MPNowPlayingInfoCenter.default().nowPlayingInfo = nil
            return
        }
        
        let word = item.word
        
        // æ„å»ºæ ‡é¢˜å’Œè‰ºæœ¯å®¶ä¿¡æ¯
        var title = word.word
        var artist = word.phonetic ?? ""
        
        // å¦‚æœæœ‰é‡Šä¹‰ï¼Œæ·»åŠ åˆ°è‰ºæœ¯å®¶ä¿¡æ¯
        if let meaning = word.meaning, !meaning.isEmpty {
            let simplifiedMeaning = meaning.components(separatedBy: "ï¼›").first ?? meaning
            artist = artist.isEmpty ? simplifiedMeaning : "\(artist) - \(simplifiedMeaning)"
        }
        
        // æ·»åŠ éŸ³é¢‘æ¥æºæ ‡è¯†
        let sourceIcon: String
        switch item.audioSource {
        case .documents: sourceIcon = "ğŸ“"
        case .bundle: sourceIcon = "ğŸ“¦"
        case .audioExamples: sourceIcon = "ğŸµ"
        case .online: sourceIcon = "ğŸŒ"
        case .tts: sourceIcon = "ğŸ”Š"
        case .unknown: sourceIcon = ""
        }
        
        var info: [String: Any] = [
            MPMediaItemPropertyTitle: "\(sourceIcon) \(title)",
            MPMediaItemPropertyArtist: artist,
            MPMediaItemPropertyAlbumTitle: "EarWords ç£¨è€³æœµ (\(currentIndex + 1)/\(queue.count))",
            MPNowPlayingInfoPropertyPlaybackRate: currentState == .playing ? playbackSpeed : 0,
            MPMediaItemPropertyPlaybackDuration: totalDuration,
            MPNowPlayingInfoPropertyElapsedPlaybackTime: currentTime
        ]
        
        // å¦‚æœæœ‰ä¾‹å¥ï¼Œæ·»åŠ åˆ°ä½œæ›²å®¶å­—æ®µ
        if let example = word.example, !example.isEmpty {
            info[MPMediaItemPropertyComposer] = example
        }
        
        // æ·»åŠ ä¸“è¾‘å°é¢
        let artworkImage = generateArtwork(for: word)
        let artwork = MPMediaItemArtwork(boundsSize: artworkImage.size) { _ in artworkImage }
        info[MPMediaItemPropertyArtwork] = artwork
        
        MPNowPlayingInfoCenter.default().nowPlayingInfo = info
    }
    
    /// ç”Ÿæˆé”å±å°é¢
    private func generateArtwork(for word: WordEntity) -> UIImage {
        let size = CGSize(width: 400, height: 400)
        UIGraphicsBeginImageContextWithOptions(size, false, 0)
        defer { UIGraphicsEndImageContext() }
        
        // æ ¹æ®éŸ³é¢‘æ¥æºé€‰æ‹©æ¸å˜è‰²
        let colors: [CGColor]
        switch currentAudioSource {
        case .documents:
            colors = [UIColor.systemBlue.cgColor, UIColor.systemIndigo.cgColor]
        case .bundle:
            colors = [UIColor.systemPurple.cgColor, UIColor.systemPink.cgColor]
        case .audioExamples:
            colors = [UIColor.systemGreen.cgColor, UIColor.systemTeal.cgColor]
        case .online:
            colors = [UIColor.systemOrange.cgColor, UIColor.systemRed.cgColor]
        case .tts:
            colors = [UIColor.systemGray.cgColor, UIColor.systemGray2.cgColor]
        case .unknown:
            colors = [UIColor.purple.cgColor, UIColor.blue.cgColor]
        }
        
        // ç»˜åˆ¶æ¸å˜èƒŒæ™¯
        let context = UIGraphicsGetCurrentContext()!
        let gradient = CGGradient(colorsSpace: CGColorSpaceCreateDeviceRGB(),
                                  colors: colors as CFArray,
                                  locations: [0, 1])!
        context.drawLinearGradient(gradient,
                                   start: CGPoint(x: 0, y: 0),
                                   end: CGPoint(x: size.width, y: size.height),
                                   options: [])
        
        // ç»˜åˆ¶è£…é¥°åœ†ç¯
        let circlePath = UIBezierPath(arcCenter: CGPoint(x: size.width/2, y: size.height/2 - 20),
                                      radius: 120,
                                      startAngle: 0,
                                      endAngle: .pi * 2,
                                      clockwise: true)
        circlePath.lineWidth = 4
        UIColor.white.withAlphaComponent(0.3).setStroke()
        circlePath.stroke()
        
        // ç»˜åˆ¶å•è¯æ–‡æœ¬
        let paragraphStyle = NSMutableParagraphStyle()
        paragraphStyle.alignment = .center
        
        let attributes: [NSAttributedString.Key: Any] = [
            .font: UIFont.systemFont(ofSize: 52, weight: .bold),
            .foregroundColor: UIColor.white,
            .paragraphStyle: paragraphStyle
        ]
        
        let textSize = word.word.size(withAttributes: attributes)
        let textRect = CGRect(
            x: (size.width - textSize.width) / 2,
            y: (size.height - textSize.height) / 2 - 20,
            width: textSize.width,
            height: textSize.height
        )
        word.word.draw(in: textRect, withAttributes: attributes)
        
        // ç»˜åˆ¶éŸ³æ ‡
        if let phonetic = word.phonetic {
            let phoneticAttributes: [NSAttributedString.Key: Any] = [
                .font: UIFont.systemFont(ofSize: 26),
                .foregroundColor: UIColor.white.withAlphaComponent(0.9),
                .paragraphStyle: paragraphStyle
            ]
            let phoneticSize = phonetic.size(withAttributes: phoneticAttributes)
            let phoneticRect = CGRect(
                x: (size.width - phoneticSize.width) / 2,
                y: textRect.maxY + 16,
                width: phoneticSize.width,
                height: phoneticSize.height
            )
            phonetic.draw(in: phoneticRect, withAttributes: phoneticAttributes)
        }
        
        // ç»˜åˆ¶æ¥æºæ ‡è¯†
        let sourceText: String
        switch currentAudioSource {
        case .documents: sourceText = "æœ¬åœ°éŸ³é¢‘"
        case .bundle: sourceText = "å†…ç½®éŸ³é¢‘"
        case .audioExamples: sourceText = "ç¤ºä¾‹éŸ³é¢‘"
        case .online: sourceText = "åœ¨çº¿éŸ³é¢‘"
        case .tts: sourceText = "è¯­éŸ³åˆæˆ"
        case .unknown: sourceText = ""
        }
        
        if !sourceText.isEmpty {
            let sourceAttributes: [NSAttributedString.Key: Any] = [
                .font: UIFont.systemFont(ofSize: 14),
                .foregroundColor: UIColor.white.withAlphaComponent(0.6),
                .paragraphStyle: paragraphStyle
            ]
            let sourceSize = sourceText.size(withAttributes: sourceAttributes)
            let sourceRect = CGRect(
                x: (size.width - sourceSize.width) / 2,
                y: size.height - 50,
                width: sourceSize.width,
                height: sourceSize.height
            )
            sourceText.draw(in: sourceRect, withAttributes: sourceAttributes)
        }
        
        return UIGraphicsGetImageFromCurrentImageContext() ?? UIImage()
    }
    
    // MARK: - å·¥å…·æ–¹æ³•
    
    private func getDocumentsDirectory() -> URL {
        FileManager.default.urls(for: .documentDirectory, in: .userDomainMask).first!
    }
    
    private func getAudioExamplesDirectory() -> URL {
        // é¦–å…ˆå°è¯•Bundleä¸­çš„Data/audio-examples
        let bundlePath = Bundle.main.bundleURL.appendingPathComponent("Data/audio-examples")
        if FileManager.default.fileExists(atPath: bundlePath.path) {
            return bundlePath
        }
        
        // å°è¯•å…¶ä»–å¯èƒ½çš„è·¯å¾„
        let possiblePaths = [
            FileManager.default.urls(for: .documentDirectory, in: .userDomainMask).first!.appendingPathComponent("audio-examples"),
            URL(fileURLWithPath: "/Users/nutllwhy/.openclaw/workspace/plans/earwords/data/audio-examples")
        ]
        
        for path in possiblePaths {
            if FileManager.default.fileExists(atPath: path.path) {
                return path
            }
        }
        
        return bundlePath  // é»˜è®¤è¿”å›bundleè·¯å¾„
    }
    
    /// è®¾ç½®æ’­æ”¾æ¨¡å¼
    func setPlaybackMode(_ mode: PlaybackMode) {
        guard playbackMode != mode else { return }
        
        playbackMode = mode
        
        // ä¿å­˜å½“å‰æ’­æ”¾é¡¹
        let currentItemId = currentItem?.id
        
        // é‡æ–°æ’åºé˜Ÿåˆ—
        switch mode {
        case .sequential:
            // æŒ‰ ID æ’åºæ¢å¤åŸå§‹é¡ºåº
            queue.sort { $0.word.id < $1.word.id }
            
        case .random:
            queue.shuffle()
            
        case .spaced:
            sortQueueBySpacedRepetition()
        }
        
        // æ›´æ–°å½“å‰ç´¢å¼•
        if let id = currentItemId,
           let newIndex = queue.firstIndex(where: { $0.id == id }) {
            currentIndex = newIndex
        }
        
        print("ğŸ”„ æ’­æ”¾æ¨¡å¼åˆ‡æ¢ä¸º: \(mode.rawValue)")
    }
    
    /// æ¸…ç©ºé˜Ÿåˆ—
    func clearQueue() {
        stop()
        queue.removeAll()
        originalQueue.removeAll()
        currentItem = nil
        currentIndex = 0
    }
    
    /// è·å–æ’­æ”¾ç»Ÿè®¡
    func getPlaybackStats() -> PlaybackStats {
        let totalWords = queue.count
        let totalPlayCount = queue.reduce(0) { $0 + $1.playCount }
        let avgPriority = queue.isEmpty ? 0 : queue.reduce(0.0) { $0 + $1.priority } / Double(queue.count)
        
        return PlaybackStats(
            totalWords: totalWords,
            totalPlayCount: totalPlayCount,
            averagePriority: avgPriority,
            audioSourceBreakdown: getAudioSourceBreakdown()
        )
    }
    
    /// è·å–éŸ³é¢‘æ¥æºåˆ†å¸ƒ
    private func getAudioSourceBreakdown() -> [AudioSource: Int] {
        var breakdown: [AudioSource: Int] = [:]
        for item in queue {
            breakdown[item.audioSource, default: 0] += 1
        }
        return breakdown
    }
}

// MARK: - AVAudioPlayerDelegate

extension AudioPlayerManager: AVAudioPlayerDelegate {
    func audioPlayerDidFinishPlaying(_ player: AVAudioPlayer, successfully flag: Bool) {
        currentState = .finished
        
        // æ›´æ–°å½“å‰é¡¹ç»Ÿè®¡
        if currentItem != nil {
            updateCurrentItemStats()
        }
        
        // è‡ªåŠ¨æ’­æ”¾ä¸‹ä¸€é¦–
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) { [weak self] in
            self?.nextTrack()
        }
    }
    
    func audioPlayerDecodeErrorDidOccur(_ player: AVAudioPlayer, error: Error?) {
        currentState = .error(error?.localizedDescription ?? "è§£ç é”™è¯¯")
        print("âŒ éŸ³é¢‘è§£ç é”™è¯¯: \(error?.localizedDescription ?? "æœªçŸ¥")")
    }
}

// MARK: - AVSpeechSynthesizerDelegate

extension AudioPlayerManager: AVSpeechSynthesizerDelegate {
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didFinish utterance: AVSpeechUtterance) {
        if currentAudioSource == .tts {
            ttsDidFinish()
        }
    }
    
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didCancel utterance: AVSpeechUtterance) {
        if currentAudioSource == .tts {
            stopProgressTimer()
        }
    }
}

// MARK: - æ’­æ”¾ç»Ÿè®¡

struct PlaybackStats {
    let totalWords: Int
    let totalPlayCount: Int
    let averagePriority: Double
    let audioSourceBreakdown: [AudioSource: Int]
}

// MARK: - è¾…åŠ©æ‰©å±•

extension TimeInterval {
    var formatted: String {
        guard self.isFinite && self >= 0 else { return "0:00" }
        let minutes = Int(self) / 60
        let seconds = Int(self) % 60
        return String(format: "%d:%02d", minutes, seconds)
    }
}
